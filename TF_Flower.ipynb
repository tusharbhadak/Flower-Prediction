{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractict the zip file.\n",
    "zip_file = tf.keras.utils.get_file(origin=\"E:\\TF_Flower\\fp.zip\", fname = \"fp.zip\", extract=True , cache_subdir=\"E:\\TF_Flower\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.path.dirname(zip_file), \"fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5935 images belonging to 102 classes.\n",
      "Found 1435 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 244\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "#PreProcessing the data.\n",
    "data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "#Train Data\n",
    "train_generator = data.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "#Validation Data\n",
    "val_generator = data.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alpine sea holly': 0, 'Anthurium': 1, 'Artichoke': 2, 'Azalea': 3, 'Ball moss': 4, 'Balloon flower': 5, 'Barbeton daisy': 6, 'Bearded iris': 7, 'Bee balm': 8, 'Bird of paradise': 9, 'Bishop of llandaff': 10, 'Black-eyed susan': 11, 'Blackberry lily': 12, 'Blanket flower': 13, 'Bolero deep blue': 14, 'Bougainvillea': 15, 'Bromelia': 16, 'Buttercup': 17, 'Californian poppy': 18, 'Camellia': 19, 'Canna lily': 20, 'Canterbury bells': 21, 'Cape flower': 22, 'Carnation': 23, 'Cautleya spicata': 24, 'Clematis': 25, \"Colt's foot\": 26, 'Columbine': 27, 'Common dandelion': 28, 'Corn poppy': 29, 'Cyclamen': 30, 'Daffodil': 31, 'Desert-rose': 32, 'English marigold': 33, 'Fire lily': 34, 'Foxglove': 35, 'Frangipani': 36, 'Fritillary': 37, 'Garden phlox': 38, 'Gaura': 39, 'Gazania': 40, 'Geranium': 41, 'Giant white arum lily': 42, 'Globe thistle': 43, 'Globe-flower': 44, 'Grape hyacinth': 45, 'Great masterwort': 46, 'Hard-leaved pocket orchid': 47, 'Hibiscus': 48, 'Hippeastrum': 49, 'Japanese anemone': 50, 'King protea': 51, 'Lenten rose': 52, 'Lotus': 53, 'Love in the mist': 54, 'Magnolia': 55, 'Mallow': 56, 'Marigold': 57, 'Mexican aster': 58, 'Mexican petunia': 59, 'Monkshood': 60, 'Moon orchid': 61, 'Morning glory': 62, 'Orange dahlia': 63, 'Osteospermum': 64, 'Oxeye daisy': 65, 'Passion flower': 66, 'Pelargonium': 67, 'Peruvian lily': 68, 'Petunia': 69, 'Pincushion flower': 70, 'Pink primrose': 71, 'Pink-yellow dahlia': 72, 'Poinsettia': 73, 'Primula': 74, 'Prince of wales feathers': 75, 'Purple coneflower': 76, 'Red ginger': 77, 'Rose': 78, 'Ruby-lipped cattleya': 79, 'Siam tulip': 80, 'Silverbush': 81, 'Snapdragon': 82, 'Spear thistle': 83, 'Spring crocus': 84, 'Stemless gentian': 85, 'Sunflower': 86, 'Sweet pea': 87, 'Sweet william': 88, 'Sword lily': 89, 'Thorn apple': 90, 'Tiger lily': 91, 'Toad lily': 92, 'Tree mallow': 93, 'Tree poppy': 94, 'Trumpet creeper': 95, 'Wallflower': 96, 'Water lily': 97, 'Watercress': 98, 'Wild pansy': 99, 'Windflower': 100, 'Yellow iris': 101}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "w : Opens in write-only mode. The pointer is placed at the beginning of the file and this will overwrite any existing file with the same name.\n",
    "It will create a new file if one with the same name doesn't exist.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "    f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "##MobileNetV2 :- MobileNetV2 is a significant improvement over MobileNetV1 and pushes the state of the art for mobile visual recognition including classification, object detection and semantic segmentation.\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freezing the model\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(102, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 613s 13s/step - loss: 4.3555 - accuracy: 0.0739 - val_loss: 3.2603 - val_accuracy: 0.2892\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 325s 7s/step - loss: 2.8513 - accuracy: 0.3684 - val_loss: 2.1010 - val_accuracy: 0.4983\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 312s 7s/step - loss: 1.6770 - accuracy: 0.5932 - val_loss: 1.5687 - val_accuracy: 0.5958\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 1867s 40s/step - loss: 1.0434 - accuracy: 0.7394 - val_loss: 1.2730 - val_accuracy: 0.6683\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 326s 7s/step - loss: 0.8050 - accuracy: 0.7870 - val_loss: 1.1863 - val_accuracy: 0.6927\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 316s 7s/step - loss: 0.6447 - accuracy: 0.8397 - val_loss: 1.0516 - val_accuracy: 0.7220\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 315s 7s/step - loss: 0.5208 - accuracy: 0.8738 - val_loss: 1.0140 - val_accuracy: 0.7352\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 326s 7s/step - loss: 0.4335 - accuracy: 0.8902 - val_loss: 0.9936 - val_accuracy: 0.7463\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 362s 8s/step - loss: 0.3654 - accuracy: 0.9153 - val_loss: 0.9312 - val_accuracy: 0.7666\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 355s 8s/step - loss: 0.3204 - accuracy: 0.9283 - val_loss: 0.9646 - val_accuracy: 0.7491\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 347s 7s/step - loss: 0.2736 - accuracy: 0.9387 - val_loss: 0.9075 - val_accuracy: 0.7679\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 360s 8s/step - loss: 0.2332 - accuracy: 0.9556 - val_loss: 0.9239 - val_accuracy: 0.7589\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 353s 8s/step - loss: 0.1989 - accuracy: 0.9628 - val_loss: 0.9114 - val_accuracy: 0.7652\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 350s 7s/step - loss: 0.1838 - accuracy: 0.9684 - val_loss: 0.9232 - val_accuracy: 0.7610\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 352s 8s/step - loss: 0.1608 - accuracy: 0.9702 - val_loss: 0.8979 - val_accuracy: 0.7714\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 357s 8s/step - loss: 0.1403 - accuracy: 0.9732 - val_loss: 0.8841 - val_accuracy: 0.7742\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 352s 8s/step - loss: 0.1175 - accuracy: 0.9807 - val_loss: 0.8720 - val_accuracy: 0.7784\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 335s 7s/step - loss: 0.1037 - accuracy: 0.9855 - val_loss: 0.8889 - val_accuracy: 0.7693\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 330s 7s/step - loss: 0.1029 - accuracy: 0.9843 - val_loss: 0.8859 - val_accuracy: 0.7847\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 315s 7s/step - loss: 0.0903 - accuracy: 0.9860 - val_loss: 0.8932 - val_accuracy: 0.7728\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"\"\n",
    "tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "wb : Opens a write-only file in binary mode.\n",
    "\"\"\"\n",
    "\n",
    "with open('modelflow.tflite','wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
